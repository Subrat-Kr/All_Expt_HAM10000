{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rqsi-MLzpMg7"
   },
   "source": [
    "algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9Abe_NTpain",
    "outputId": "8d87c505-13c3-422c-ec01-196d2dcd9e2f"
   },
   "outputs": [],
   "source": [
    "# cd JoCoR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_gcmfi-yp42j",
    "outputId": "e55a6d50-0f29-442e-a701-8d238c50f653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/subrat/JoCoR-env/JoCoR\n"
     ]
    }
   ],
   "source": [
    "# cd JoCoR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "YsmtvNbypPWi"
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from JoCoR.model.cnn import MLPNet,CNN\n",
    "import numpy as np\n",
    "from JoCoR.common.utils import accuracy\n",
    "\n",
    "from JoCoR.algorithm.loss import loss_jocor\n",
    "\n",
    "\n",
    "class JoCoR:\n",
    "    def __init__(self, args, train_dataset, device, input_channel, num_classes):\n",
    "\n",
    "        # Hyper Parameters\n",
    "        self.batch_size = 128\n",
    "        learning_rate = args.lr\n",
    "\n",
    "#         if args.forget_rate is None:\n",
    "#             if args.noise_type == \"asymmetric\":\n",
    "#                 forget_rate = args.noise_rate / 2\n",
    "#             else:\n",
    "#                 forget_rate = args.noise_rate\n",
    "#         else:\n",
    "#             forget_rate = args.forget_rate\n",
    "\n",
    "#         self.noise_or_not = train_dataset.noise_or_not\n",
    "\n",
    "        # Adjust learning rate and betas for Adam Optimizer\n",
    "        mom1 = 0.9\n",
    "        mom2 = 0.1\n",
    "        self.alpha_plan = [learning_rate] * args.n_epoch\n",
    "        self.beta1_plan = [mom1] * args.n_epoch\n",
    "\n",
    "        for i in range(args.epoch_decay_start, args.n_epoch):\n",
    "            self.alpha_plan[i] = float(args.n_epoch - i) / (args.n_epoch - args.epoch_decay_start) * learning_rate\n",
    "            self.beta1_plan[i] = mom2\n",
    "\n",
    "        # define drop rate schedule\n",
    "        self.rate_schedule = np.ones(args.n_epoch) * forget_rate\n",
    "        self.rate_schedule[:args.num_gradual] = np.linspace(0, forget_rate ** args.exponent, args.num_gradual)\n",
    "\n",
    "        self.device = device\n",
    "        self.num_iter_per_epoch = args.num_iter_per_epoch\n",
    "        self.print_freq = args.print_freq\n",
    "        self.co_lambda = args.co_lambda\n",
    "        self.n_epoch = args.n_epoch\n",
    "        self.train_dataset = train_dataset\n",
    "\n",
    "        if args.model_type == \"googlenet\":\n",
    "            self.model1 = torchvision.models.googlenet(pretrained=True)\n",
    "            self.model2 = torchvision.models.googlenet(pretrained=True)\n",
    "        elif args.model_type == \"mlp\":\n",
    "            self.model1 = MLPnet()\n",
    "            self.model2 = MLPnet()\n",
    "\n",
    "        self.model1.to(device)\n",
    "        print(self.model1.parameters)\n",
    "\n",
    "        self.model2.to(device)\n",
    "        print(self.model2.parameters)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(list(self.model1.parameters()) + list(self.model2.parameters()),\n",
    "                                          lr=learning_rate)\n",
    "\n",
    "        self.loss_fn = loss_jocor\n",
    "\n",
    "\n",
    "        self.adjust_lr = args.adjust_lr\n",
    "\n",
    "    # Evaluate the Model\n",
    "    def evaluate(self, test_loader):\n",
    "        print('Evaluating ...')\n",
    "        self.model1.eval()  # Change model to 'eval' mode.\n",
    "        self.model2.eval()  # Change model to 'eval' mode\n",
    "\n",
    "        correct1 = 0\n",
    "        total1 = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = Variable(images).to(self.device)\n",
    "            logits1 = self.model1(images)\n",
    "            outputs1 = F.softmax(logits1, dim=1)\n",
    "            _, pred1 = torch.max(outputs1.data, 1)\n",
    "            total1 += labels.size(0)\n",
    "            correct1 += (pred1.cpu() == labels).sum()\n",
    "\n",
    "        correct2 = 0\n",
    "        total2 = 0\n",
    "        for images, labels, _ in test_loader:\n",
    "            images = Variable(images).to(self.device)\n",
    "            logits2 = self.model2(images)\n",
    "            outputs2 = F.softmax(logits2, dim=1)\n",
    "            _, pred2 = torch.max(outputs2.data, 1)\n",
    "            total2 += labels.size(0)\n",
    "            correct2 += (pred2.cpu() == labels).sum()\n",
    "\n",
    "        acc1 = 100 * float(correct1) / float(total1)\n",
    "        acc2 = 100 * float(correct2) / float(total2)\n",
    "        return acc1, acc2\n",
    "\n",
    "    # Train the Model\n",
    "    def train(self, train_loader, epoch):\n",
    "        print('Training ...')\n",
    "        self.model1.train()  # Change model to 'train' mode.\n",
    "        self.model2.train()  # Change model to 'train' mode\n",
    "\n",
    "        if self.adjust_lr == 1:\n",
    "            self.adjust_learning_rate(self.optimizer, epoch)\n",
    "\n",
    "        train_total = 0\n",
    "        train_correct = 0\n",
    "        train_total2 = 0\n",
    "        train_correct2 = 0\n",
    "        pure_ratio_1_list = []\n",
    "        pure_ratio_2_list = []\n",
    "\n",
    "        for i, (images, labels, indexes) in enumerate(train_loader):\n",
    "            ind = indexes.cpu().numpy().transpose()\n",
    "            if i > self.num_iter_per_epoch:\n",
    "                break\n",
    "\n",
    "            images = Variable(images).to(self.device)\n",
    "            labels = Variable(labels).to(self.device)\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            logits1 = self.model1(images)\n",
    "            prec1 = accuracy(logits1, labels, topk=(1,))\n",
    "            train_total += 1\n",
    "            train_correct += prec1\n",
    "\n",
    "            logits2 = self.model2(images)\n",
    "            prec2 = accuracy(logits2, labels, topk=(1,))\n",
    "            train_total2 += 1\n",
    "            train_correct2 += prec2\n",
    "\n",
    "            loss_1, loss_2, pure_ratio_1, pure_ratio_2 = self.loss_fn(logits1, logits2, labels, self.rate_schedule[epoch],\n",
    "                                                                 ind, self.noise_or_not, self.co_lambda)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss_1.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pure_ratio_1_list.append(100 * pure_ratio_1)\n",
    "            pure_ratio_2_list.append(100 * pure_ratio_2)\n",
    "\n",
    "            if (i + 1) % self.print_freq == 0:\n",
    "                print(\n",
    "                    'Epoch [%d/%d], Iter [%d/%d] Training Accuracy1: %.4F, Training Accuracy2: %.4f, Loss1: %.4f, Loss2: %.4f, Pure Ratio1 %.4f %% Pure Ratio2 %.4f %%'\n",
    "                    % (epoch + 1, self.n_epoch, i + 1, len(self.train_dataset) // self.batch_size, prec1, prec2,\n",
    "                       loss_1.data.item(), loss_2.data.item(), sum(pure_ratio_1_list) / len(pure_ratio_1_list), sum(pure_ratio_2_list) / len(pure_ratio_2_list)))\n",
    "\n",
    "        train_acc1 = float(train_correct) / float(train_total)\n",
    "        train_acc2 = float(train_correct2) / float(train_total2)\n",
    "        return train_acc1, train_acc2, pure_ratio_1_list, pure_ratio_2_list\n",
    "\n",
    "    def adjust_learning_rate(self, optimizer, epoch):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = self.alpha_plan[epoch]\n",
    "            param_group['betas'] = (self.beta1_plan[epoch], 0.999)  # Only change beta1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCczmErwqB62"
   },
   "source": [
    "loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "rtYi38HhqFM4"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def kl_loss_compute(pred, soft_targets, reduce=True):\n",
    "\n",
    "    kl = F.kl_div(F.log_softmax(pred, dim=1),F.softmax(soft_targets, dim=1),reduce=False)\n",
    "\n",
    "    if reduce:\n",
    "        return torch.mean(torch.sum(kl, dim=1))\n",
    "    else:\n",
    "        return torch.sum(kl, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_jocor(y_1, y_2, t, forget_rate, ind, noise_or_not, co_lambda=0.1):\n",
    "\n",
    "    loss_pick_1 = F.cross_entropy(y_1, t, reduce = False) * (1-co_lambda)\n",
    "    loss_pick_2 = F.cross_entropy(y_2, t, reduce = False) * (1-co_lambda)\n",
    "    loss_pick = (loss_pick_1 + loss_pick_2 + co_lambda * kl_loss_compute(y_1, y_2,reduce=False) + co_lambda * kl_loss_compute(y_2, y_1, reduce=False)).cpu()\n",
    "\n",
    "\n",
    "    ind_sorted = np.argsort(loss_pick.data)\n",
    "    loss_sorted = loss_pick[ind_sorted]\n",
    "\n",
    "    remember_rate = 1 - forget_rate\n",
    "    num_remember = int(remember_rate * len(loss_sorted))\n",
    "\n",
    "    pure_ratio = np.sum(noise_or_not[ind[ind_sorted[:num_remember]]])/float(num_remember)\n",
    "\n",
    "    ind_update=ind_sorted[:num_remember]\n",
    "\n",
    "    # exchange\n",
    "    loss = torch.mean(loss_pick[ind_update])\n",
    "\n",
    "    return loss, loss, pure_ratio, pure_ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCX0K54AqQH_"
   },
   "source": [
    "common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "A6AMDRFJqROd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def plot_result(accuracy_list,pure_ratio_list,name=\"test.png\"):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(accuracy_list, label='test_accuracy')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(pure_ratio_list, label='test_pure_ratio')\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def accuracy(logit, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    output = F.softmax(logit, dim=1)\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y7tTNiMqZQu"
   },
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKYD_FcsqaKX"
   },
   "source": [
    "cifar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "kxX9-Vwpq5KH"
   },
   "outputs": [],
   "source": [
    "#!pip uninstall noisify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "7-Lt2PbNtuwo"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import os.path\n",
    "# import copy\n",
    "# import hashlib\n",
    "# import errno\n",
    "# import numpy as np\n",
    "# from numpy.testing import assert_array_almost_equal\n",
    "\n",
    "# # def check_integrity(fpath, md5):\n",
    "# #     if not os.path.isfile(fpath):\n",
    "# #         return False\n",
    "# #     md5o = hashlib.md5()\n",
    "# #     with open(fpath, 'rb') as f:\n",
    "# #         # read in 1MB chunks\n",
    "# #         for chunk in iter(lambda: f.read(1024 * 1024), b''):\n",
    "# #             md5o.update(chunk)\n",
    "# #     md5c = md5o.hexdigest()\n",
    "# #     if md5c != md5:\n",
    "# #         return False\n",
    "# #     return True\n",
    "\n",
    "\n",
    "# # def download_url(url, root, filename, md5):\n",
    "# #     from six.moves import urllib\n",
    "\n",
    "# #     root = os.path.expanduser(root)\n",
    "# #     fpath = os.path.join(root, filename)\n",
    "\n",
    "# #     try:\n",
    "# #         os.makedirs(root)\n",
    "# #     except OSError as e:\n",
    "# #         if e.errno == errno.EEXIST:\n",
    "# #             pass\n",
    "# #         else:\n",
    "# #             raise\n",
    "\n",
    "# #     # downloads file\n",
    "# #     if os.path.isfile(fpath) and check_integrity(fpath, md5):\n",
    "# #         print('Using downloaded and verified file: ' + fpath)\n",
    "# #     else:\n",
    "# #         try:\n",
    "# #             print('Downloading ' + url + ' to ' + fpath)\n",
    "# #             urllib.request.urlretrieve(url, fpath)\n",
    "# #         except:\n",
    "# #             if url[:5] == 'https':\n",
    "# #                 url = url.replace('https:', 'http:')\n",
    "# #                 print('Failed download. Trying https -> http instead.'\n",
    "# #                       ' Downloading ' + url + ' to ' + fpath)\n",
    "# #                 urllib.request.urlretrieve(url, fpath)\n",
    "\n",
    "\n",
    "# def list_dir(root, prefix=False):\n",
    "#     \"\"\"List all directories at a given root\n",
    "\n",
    "#     Args:\n",
    "#         root (str): Path to directory whose folders need to be listed\n",
    "#         prefix (bool, optional): If true, prepends the path to each result, otherwise\n",
    "#             only returns the name of the directories found\n",
    "#     \"\"\"\n",
    "#     root = os.path.expanduser(root)\n",
    "#     directories = list(\n",
    "#         filter(\n",
    "#             lambda p: os.path.isdir(os.path.join(root, p)),\n",
    "#             os.listdir(root)\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     if prefix is True:\n",
    "#         directories = [os.path.join(root, d) for d in directories]\n",
    "\n",
    "#     return directories\n",
    "\n",
    "\n",
    "# def list_files(root, suffix, prefix=False):\n",
    "#     \"\"\"List all files ending with a suffix at a given root\n",
    "\n",
    "#     Args:\n",
    "#         root (str): Path to directory whose folders need to be listed\n",
    "#         suffix (str or tuple): Suffix of the files to match, e.g. '.png' or ('.jpg', '.png').\n",
    "#             It uses the Python \"str.endswith\" method and is passed directly\n",
    "#         prefix (bool, optional): If true, prepends the path to each result, otherwise\n",
    "#             only returns the name of the files found\n",
    "#     \"\"\"\n",
    "#     root = os.path.expanduser(root)\n",
    "#     files = list(\n",
    "#         filter(\n",
    "#             lambda p: os.path.isfile(os.path.join(root, p)) and p.endswith(suffix),\n",
    "#             os.listdir(root)\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     if prefix is True:\n",
    "#         files = [os.path.join(root, d) for d in files]\n",
    "\n",
    "#     return files\n",
    "\n",
    "\n",
    "# def build_for_cifar100(size, noise):\n",
    "#     \"\"\" The noise matrix flips to the \"next\" class with probability 'noise'.\n",
    "#     \"\"\"\n",
    "\n",
    "#     assert(noise >= 0.) and (noise <= 1.)\n",
    "\n",
    "#     P = (1. - noise) * np.eye(size)\n",
    "#     for i in np.arange(size - 1):\n",
    "#         P[i, i+1] = noise\n",
    "\n",
    "#     # adjust last row\n",
    "#     P[size-1, 0] = noise\n",
    "\n",
    "#     assert_array_almost_equal(P.sum(axis=1), 1, 1)\n",
    "#     return P\n",
    "\n",
    "\n",
    "# # basic function\n",
    "# def multiclass_noisify(y, P, random_state=0):\n",
    "#     \"\"\" Flip classes according to transition probability matrix T.\n",
    "#     It expects a number between 0 and the number of classes - 1.\n",
    "#     \"\"\"\n",
    "#     print(np.max(y), P.shape[0])\n",
    "#     assert P.shape[0] == P.shape[1]\n",
    "#     assert np.max(y) < P.shape[0]\n",
    "\n",
    "#     # row stochastic matrix\n",
    "#     assert_array_almost_equal(P.sum(axis=1), np.ones(P.shape[1]))\n",
    "#     assert (P >= 0.0).all()\n",
    "\n",
    "#     m = y.shape[0]\n",
    "#     print(m)\n",
    "#     new_y = y.copy()\n",
    "#     flipper = np.random.RandomState(random_state)\n",
    "\n",
    "#     for idx in np.arange(m):\n",
    "#         i = y[idx]\n",
    "#         # draw a vector with only an 1\n",
    "#         flipped = flipper.multinomial(1, P[i, :][0], 1)[0]\n",
    "#         new_y[idx] = np.where(flipped == 1)[0]\n",
    "\n",
    "#     return new_y\n",
    "\n",
    "\n",
    "# # noisify_pairflip call the function \"multiclass_noisify\"\n",
    "# def noisify_pairflip(y_train, noise, random_state=None, nb_classes=10):\n",
    "#     \"\"\"mistakes:\n",
    "#         flip in the pair\n",
    "#     \"\"\"\n",
    "#     P = np.eye(nb_classes)\n",
    "#     n = noise\n",
    "\n",
    "#     if n > 0.0:\n",
    "#         # 0 -> 1\n",
    "#         P[0, 0], P[0, 1] = 1. - n, n\n",
    "#         for i in range(1, nb_classes-1):\n",
    "#             P[i, i], P[i, i + 1] = 1. - n, n\n",
    "#         P[nb_classes-1, nb_classes-1], P[nb_classes-1, 0] = 1. - n, n\n",
    "\n",
    "#         y_train_noisy = multiclass_noisify(y_train, P=P,\n",
    "#                                            random_state=random_state)\n",
    "#         actual_noise = (y_train_noisy != y_train).mean()\n",
    "#         assert actual_noise > 0.0\n",
    "#         print('Actual noise %.2f' % actual_noise)\n",
    "#         y_train = y_train_noisy\n",
    "#     print(P)\n",
    "\n",
    "#     return y_train, actual_noise\n",
    "\n",
    "# def noisify_multiclass_symmetric(y_train, noise, random_state=None, nb_classes=10):\n",
    "#     \"\"\"mistakes:\n",
    "#         flip in the symmetric way\n",
    "#     \"\"\"\n",
    "#     P = np.ones((nb_classes, nb_classes))\n",
    "#     n = noise\n",
    "#     P = (n / (nb_classes - 1)) * P\n",
    "\n",
    "#     if n > 0.0:\n",
    "#         # 0 -> 1\n",
    "#         P[0, 0] = 1. - n\n",
    "#         for i in range(1, nb_classes-1):\n",
    "#             P[i, i] = 1. - n\n",
    "#         P[nb_classes-1, nb_classes-1] = 1. - n\n",
    "\n",
    "#         y_train_noisy = multiclass_noisify(y_train, P=P,\n",
    "#                                            random_state=random_state)\n",
    "#         actual_noise = (y_train_noisy != y_train).mean()\n",
    "#         assert actual_noise > 0.0\n",
    "#         print('Actual noise %.2f' % actual_noise)\n",
    "#         y_train = y_train_noisy\n",
    "#     print(P)\n",
    "\n",
    "#     return y_train, actual_noise\n",
    "\n",
    "# def noisify_mnist_asymmetric(y_train, noise, random_state=None):\n",
    "#     \"\"\"mistakes:\n",
    "#         1 <- 7\n",
    "#         2 -> 7\n",
    "#         3 -> 8\n",
    "#         5 <-> 6\n",
    "#     \"\"\"\n",
    "#     nb_classes = 10\n",
    "#     P = np.eye(nb_classes)\n",
    "#     n = noise\n",
    "\n",
    "#     if n > 0.0:\n",
    "#         # 1 <- 7\n",
    "#         P[7, 7], P[7, 1] = 1. - n, n\n",
    "\n",
    "#         # 2 -> 7\n",
    "#         P[2, 2], P[2, 7] = 1. - n, n\n",
    "\n",
    "#         # 5 <-> 6\n",
    "#         P[5, 5], P[5, 6] = 1. - n, n\n",
    "#         P[6, 6], P[6, 5] = 1. - n, n\n",
    "\n",
    "#         # 3 -> 8\n",
    "#         P[3, 3], P[3, 8] = 1. - n, n\n",
    "\n",
    "#         y_train_noisy = multiclass_noisify(y_train, P=P,\n",
    "#                                            random_state=random_state)\n",
    "#         actual_noise = (y_train_noisy != y_train).mean()\n",
    "#         assert actual_noise > 0.0\n",
    "#         print('Actual noise %.2f' % actual_noise)\n",
    "#         y_train = y_train_noisy\n",
    "\n",
    "#     print(P)\n",
    "\n",
    "#     return y_train, P\n",
    "\n",
    "\n",
    "# # def noisify_cifar10_asymmetric(y_train, noise, random_state=None):\n",
    "# #     \"\"\"mistakes:\n",
    "# #         automobile <- truck\n",
    "# #         bird -> airplane\n",
    "# #         cat <-> dog\n",
    "# #         deer -> horse\n",
    "# #     \"\"\"\n",
    "# #     nb_classes = 10\n",
    "# #     P = np.eye(nb_classes)\n",
    "# #     n = noise\n",
    "\n",
    "# #     if n > 0.0:\n",
    "# #         # automobile <- truck\n",
    "# #         P[9, 9], P[9, 1] = 1. - n, n\n",
    "\n",
    "# #         # bird -> airplane\n",
    "# #         P[2, 2], P[2, 0] = 1. - n, n\n",
    "\n",
    "# #         # cat <-> dog\n",
    "# #         P[3, 3], P[3, 5] = 1. - n, n\n",
    "# #         P[5, 5], P[5, 3] = 1. - n, n\n",
    "\n",
    "# #         # automobile -> truck\n",
    "# #         P[4, 4], P[4, 7] = 1. - n, n\n",
    "\n",
    "# #         y_train_noisy = multiclass_noisify(y_train, P=P,\n",
    "# #                                            random_state=random_state)\n",
    "# #         actual_noise = (y_train_noisy != y_train).mean()\n",
    "# #         assert actual_noise > 0.0\n",
    "# #         print('Actual noise %.2f' % actual_noise)\n",
    "# #         y_train = y_train_noisy\n",
    "\n",
    "# #     return y_train, P\n",
    "\n",
    "\n",
    "# # def noisify_cifar100_asymmetric(y_train, noise, random_state=None):\n",
    "# #     \"\"\"mistakes are inside the same superclass of 10 classes, e.g. 'fish'\n",
    "# #     \"\"\"\n",
    "# #     nb_classes = 100\n",
    "# #     P = np.eye(nb_classes)\n",
    "# #     n = noise\n",
    "# #     nb_superclasses = 20\n",
    "# #     nb_subclasses = 5\n",
    "\n",
    "# #     if n > 0.0:\n",
    "# #         for i in np.arange(nb_superclasses):\n",
    "# #             init, end = i * nb_subclasses, (i+1) * nb_subclasses\n",
    "# #             P[init:end, init:end] = build_for_cifar100(nb_subclasses, n)\n",
    "\n",
    "# #         y_train_noisy = multiclass_noisify(y_train, P=P,\n",
    "# #                                            random_state=random_state)\n",
    "# #         actual_noise = (y_train_noisy != y_train).mean()\n",
    "# #         assert actual_noise > 0.0\n",
    "# #         print('Actual noise %.2f' % actual_noise)\n",
    "# #         y_train = y_train_noisy\n",
    "\n",
    "# #     return y_train, P\n",
    "\n",
    "\n",
    "def noisify(dataset='mnist', nb_classes=10, train_labels=None, noise_type=None, noise_rate=0, random_state=0):\n",
    "    if noise_type == 'pairflip':\n",
    "        train_noisy_labels, actual_noise_rate = noisify_pairflip(train_labels, noise_rate, random_state=random_state, nb_classes=nb_classes)\n",
    "    if noise_type == 'symmetric':\n",
    "        train_noisy_labels, actual_noise_rate = noisify_multiclass_symmetric(train_labels, noise_rate, random_state=random_state, nb_classes=nb_classes)\n",
    "# #     if noise_type == 'asymmetric':\n",
    "# #         if dataset == 'mnist':\n",
    "# #             train_noisy_labels, actual_noise_rate = noisify_mnist_asymmetric(train_labels, noise_rate, random_state=random_state)\n",
    "# #         elif dataset == 'cifar10':\n",
    "# #             train_noisy_labels, actual_noise_rate = noisify_cifar10_asymmetric(train_labels, noise_rate, random_state=random_state)\n",
    "# #         elif dataset == 'cifar100':\n",
    "# #             train_noisy_labels, actual_noise_rate = noisify_cifar100_asymmetric(train_labels, noise_rate, random_state=random_state)\n",
    "#     return train_noisy_labels, actual_noise_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3YHORWxvByH",
    "outputId": "2ccdbeb7-f099-4b10-b0c4-6df3b28c1a49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/subrat'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "tKAo0bkCqb4V"
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# from PIL import Image\n",
    "# import os\n",
    "# import os.path\n",
    "# import numpy as np\n",
    "# import sys\n",
    "\n",
    "# if sys.version_info[0] == 2:\n",
    "#     import cPickle as pickle\n",
    "# else:\n",
    "#     import pickle\n",
    "\n",
    "# import torch.utils.data as data\n",
    "# from utils import noisify\n",
    "\n",
    "# class CIFAR10(data.Dataset):\n",
    "#     \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "\n",
    "#     Args:\n",
    "#         root (string): Root directory of dataset where directory\n",
    "#             ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
    "#         train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "#             creates from test set.\n",
    "#         transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "#             and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "#         target_transform (callable, optional): A function/transform that takes in the\n",
    "#             target and transforms it.\n",
    "#         download (bool, optional): If true, downloads the dataset from the internet and\n",
    "#             puts it in root directory. If dataset is already downloaded, it is not\n",
    "#             downloaded again.\n",
    "\n",
    "#     \"\"\"\n",
    "# #     base_folder = 'cifar-10-batches-py'\n",
    "# #     url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "# #     filename = \"cifar-10-python.tar.gz\"\n",
    "# #     tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "# #     train_list = [\n",
    "# #         ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "# #         ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "# #         ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "# #         ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "# #         ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "# #     ]\n",
    "\n",
    "# #     test_list = [\n",
    "# #         ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "# #     ]\n",
    "\n",
    "#     def __init__(self, root, train=True,\n",
    "#                  transform=None, target_transform=None,\n",
    "#                  download=False,\n",
    "#                  noise_type=None, noise_rate=0.2, random_state=0):\n",
    "#         self.root = os.path.expanduser(root)\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "#         self.train = train  # training set or test set\n",
    "#         self.dataset='cifar10'\n",
    "#         self.noise_type=noise_type\n",
    "#         self.nb_classes=10\n",
    "\n",
    "# #         if download:\n",
    "# #             self.download()\n",
    "\n",
    "# #         if not self._check_integrity():\n",
    "# #             raise RuntimeError('Dataset not found or corrupted.' +\n",
    "# #                                ' You can use download=True to download it')\n",
    "\n",
    "#         # now load the picked numpy arrays\n",
    "#         if self.train:\n",
    "#             self.train_data = []\n",
    "#             self.train_labels = []\n",
    "#             for fentry in self.train_list:\n",
    "#                 f = fentry[0]\n",
    "#                 file = os.path.join(self.root, self.base_folder, f)\n",
    "#                 fo = open(file, 'rb')\n",
    "#                 if sys.version_info[0] == 2:\n",
    "#                     entry = pickle.load(fo)\n",
    "#                 else:\n",
    "#                     entry = pickle.load(fo, encoding='latin1')\n",
    "#                 self.train_data.append(entry['data'])\n",
    "#                 if 'labels' in entry:\n",
    "#                     self.train_labels += entry['labels']\n",
    "#                 else:\n",
    "#                     self.train_labels += entry['fine_labels']\n",
    "#                 fo.close()\n",
    "\n",
    "#             self.train_data = np.concatenate(self.train_data)\n",
    "#             self.train_data = self.train_data.reshape((50000, 3, 32, 32))\n",
    "#             self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "#             #if noise_type is not None:\n",
    "#             if noise_type !='clean':\n",
    "#                 # noisify train data\n",
    "#                 self.train_labels=np.asarray([[self.train_labels[i]] for i in range(len(self.train_labels))])\n",
    "#                 self.train_noisy_labels, self.actual_noise_rate = noisify(dataset=self.dataset, train_labels=self.train_labels, noise_type=noise_type, noise_rate=noise_rate, random_state=random_state, nb_classes=self.nb_classes)\n",
    "#                 self.train_noisy_labels=[i[0] for i in self.train_noisy_labels]\n",
    "#                 _train_labels=[i[0] for i in self.train_labels]\n",
    "#                 self.noise_or_not = np.transpose(self.train_noisy_labels)==np.transpose(_train_labels)\n",
    "#         else:\n",
    "#             f = self.test_list[0][0]\n",
    "#             file = os.path.join(self.root, self.base_folder, f)\n",
    "#             fo = open(file, 'rb')\n",
    "#             if sys.version_info[0] == 2:\n",
    "#                 entry = pickle.load(fo)\n",
    "#             else:\n",
    "#                 entry = pickle.load(fo, encoding='latin1')\n",
    "#             self.test_data = entry['data']\n",
    "#             if 'labels' in entry:\n",
    "#                 self.test_labels = entry['labels']\n",
    "#             else:\n",
    "#                 self.test_labels = entry['fine_labels']\n",
    "#             fo.close()\n",
    "#             self.test_data = self.test_data.reshape((10000, 3, 32, 32))\n",
    "#             self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             index (int): Index\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: (image, target) where target is index of the target class.\n",
    "#         \"\"\"\n",
    "#         if self.train:\n",
    "#             if self.noise_type !='clean':\n",
    "#                 img, target = self.train_data[index], self.train_noisy_labels[index]\n",
    "#             else:\n",
    "#                 img, target = self.train_data[index], self.train_labels[index]\n",
    "#         else:\n",
    "#             img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "#         # doing this so that it is consistent with all other datasets\n",
    "#         # to return a PIL Image\n",
    "#         img = Image.fromarray(img)\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "\n",
    "#         if self.target_transform is not None:\n",
    "#             target = self.target_transform(target)\n",
    "\n",
    "#         return img, target, index\n",
    "\n",
    "#     def __len__(self):\n",
    "#         if self.train:\n",
    "#             return len(self.train_data)\n",
    "#         else:\n",
    "#             return len(self.test_data)\n",
    "\n",
    "#     def _check_integrity(self):\n",
    "#         root = self.root\n",
    "#         for fentry in (self.train_list + self.test_list):\n",
    "#             filename, md5 = fentry[0], fentry[1]\n",
    "#             fpath = os.path.join(root, self.base_folder, filename)\n",
    "#             if not check_integrity(fpath, md5):\n",
    "#                 return False\n",
    "#         return True\n",
    "\n",
    "#     def download(self):\n",
    "#         import tarfile\n",
    "\n",
    "#         if self._check_integrity():\n",
    "#             print('Files already downloaded and verified')\n",
    "#             return\n",
    "\n",
    "#         root = self.root\n",
    "#         download_url(self.url, root, self.filename, self.tgz_md5)\n",
    "\n",
    "#         # extract file\n",
    "#         cwd = os.getcwd()\n",
    "#         tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
    "#         os.chdir(root)\n",
    "#         tar.extractall()\n",
    "#         tar.close()\n",
    "#         os.chdir(cwd)\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "#         fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "#         tmp = 'train' if self.train is True else 'test'\n",
    "#         fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "#         fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "#         tmp = '    Transforms (if any): '\n",
    "#         fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "#         tmp = '    Target Transforms (if any): '\n",
    "#         fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "#         return fmt_str\n",
    "\n",
    "# class CIFAR100(data.Dataset):\n",
    "#     \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "\n",
    "#     Args:\n",
    "#         root (string): Root directory of dataset where directory\n",
    "#             ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
    "#         train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "#             creates from test set.\n",
    "#         transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "#             and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "#         target_transform (callable, optional): A function/transform that takes in the\n",
    "#             target and transforms it.\n",
    "#         download (bool, optional): If true, downloads the dataset from the internet and\n",
    "#             puts it in root directory. If dataset is already downloaded, it is not\n",
    "#             downloaded again.\n",
    "\n",
    "#     \"\"\"\n",
    "#     base_folder = 'cifar-100-python'\n",
    "#     url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "#     filename = \"cifar-100-python.tar.gz\"\n",
    "#     tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "#     train_list = [\n",
    "#         ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "#     ]\n",
    "\n",
    "#     test_list = [\n",
    "#         ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "#     ]\n",
    " \n",
    "\n",
    "#     def __init__(self, root, train=True,\n",
    "#                  transform=None, target_transform=None,\n",
    "#                  download=False,\n",
    "#                  noise_type=None, noise_rate=0.2, random_state=0):\n",
    "#         self.root = os.path.expanduser(root)\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "#         self.train = train  # training set or test set\n",
    "#         self.dataset='cifar100'\n",
    "#         self.noise_type=noise_type\n",
    "#         self.nb_classes=100\n",
    "\n",
    "#         if download:\n",
    "#             self.download()\n",
    "\n",
    "#         if not self._check_integrity():\n",
    "#             raise RuntimeError('Dataset not found or corrupted.' +\n",
    "#                                ' You can use download=True to download it')\n",
    "\n",
    "#         # now load the picked numpy arrays\n",
    "#         if self.train:\n",
    "#             self.train_data = []\n",
    "#             self.train_labels = []\n",
    "#             for fentry in self.train_list:\n",
    "#                 f = fentry[0]\n",
    "#                 file = os.path.join(self.root, self.base_folder, f)\n",
    "#                 fo = open(file, 'rb')\n",
    "#                 if sys.version_info[0] == 2:\n",
    "#                     entry = pickle.load(fo)\n",
    "#                 else:\n",
    "#                     entry = pickle.load(fo, encoding='latin1')\n",
    "#                 self.train_data.append(entry['data'])\n",
    "#                 if 'labels' in entry:\n",
    "#                     self.train_labels += entry['labels']\n",
    "#                 else:\n",
    "#                     self.train_labels += entry['fine_labels']\n",
    "#                 fo.close()\n",
    "\n",
    "#             self.train_data = np.concatenate(self.train_data)\n",
    "#             self.train_data = self.train_data.reshape((50000, 3, 32, 32))\n",
    "#             self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "#             if noise_type is not None:\n",
    "#                 # noisify train data\n",
    "#                 self.train_labels=np.asarray([[self.train_labels[i]] for i in range(len(self.train_labels))])\n",
    "#                 self.train_noisy_labels, self.actual_noise_rate = noisify(dataset=self.dataset, train_labels=self.train_labels, noise_type=noise_type, noise_rate=noise_rate, random_state=random_state, nb_classes=self.nb_classes)\n",
    "#                 self.train_noisy_labels=[i[0] for i in self.train_noisy_labels]\n",
    "#                 _train_labels=[i[0] for i in self.train_labels]\n",
    "#                 self.noise_or_not = np.transpose(self.train_noisy_labels)==np.transpose(_train_labels)\n",
    "#         else:\n",
    "#             f = self.test_list[0][0]\n",
    "#             file = os.path.join(self.root, self.base_folder, f)\n",
    "#             fo = open(file, 'rb')\n",
    "#             if sys.version_info[0] == 2:\n",
    "#                 entry = pickle.load(fo)\n",
    "#             else:\n",
    "#                 entry = pickle.load(fo, encoding='latin1')\n",
    "#             self.test_data = entry['data']\n",
    "#             if 'labels' in entry:\n",
    "#                 self.test_labels = entry['labels']\n",
    "#             else:\n",
    "#                 self.test_labels = entry['fine_labels']\n",
    "#             fo.close()\n",
    "#             self.test_data = self.test_data.reshape((10000, 3, 32, 32))\n",
    "#             self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             index (int): Index\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: (image, target) where target is index of the target class.\n",
    "#         \"\"\"\n",
    "#         if self.train:\n",
    "#             if self.noise_type is not None:\n",
    "#                 img, target = self.train_data[index], self.train_noisy_labels[index]\n",
    "#             else:\n",
    "#                 img, target = self.train_data[index], self.train_labels[index]\n",
    "#         else:\n",
    "#             img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "#         # doing this so that it is consistent with all other datasets\n",
    "#         # to return a PIL Image\n",
    "#         img = Image.fromarray(img)\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "\n",
    "#         if self.target_transform is not None:\n",
    "#             target = self.target_transform(target)\n",
    "\n",
    "#         return img, target, index\n",
    "\n",
    "#     def __len__(self):\n",
    "#         if self.train:\n",
    "#             return len(self.train_data)\n",
    "#         else:\n",
    "#             return len(self.test_data)\n",
    "\n",
    "#     def _check_integrity(self):\n",
    "#         root = self.root\n",
    "#         for fentry in (self.train_list + self.test_list):\n",
    "#             filename, md5 = fentry[0], fentry[1]\n",
    "#             fpath = os.path.join(root, self.base_folder, filename)\n",
    "#             if not check_integrity(fpath, md5):\n",
    "#                 return False\n",
    "#         return True\n",
    "\n",
    "#     def download(self):\n",
    "#         import tarfile\n",
    "\n",
    "#         if self._check_integrity():\n",
    "#             print('Files already downloaded and verified')\n",
    "#             return\n",
    "\n",
    "#         root = self.root\n",
    "#         download_url(self.url, root, self.filename, self.tgz_md5)\n",
    "\n",
    "#         # extract file\n",
    "#         cwd = os.getcwd()\n",
    "#         tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
    "#         os.chdir(root)\n",
    "#         tar.extractall()\n",
    "#         tar.close()\n",
    "#         os.chdir(cwd)\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "#         fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "#         tmp = 'train' if self.train is True else 'test'\n",
    "#         fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "#         fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "#         tmp = '    Transforms (if any): '\n",
    "#         fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "#         tmp = '    Target Transforms (if any): '\n",
    "#         fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "#         return fmt_str\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "root_dir = 'JoCoR_bach/Data/train_image/'\n",
    "csv_file = 'Clean_train_data_encd.csv'\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset,DataLoader  # Gives easier dataset managment and creates mini batches\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from skimage import exposure, img_as_ubyte\n",
    "\n",
    "# class HAM10000(Dataset):\n",
    "#     def __init__(self, csv_file=\"/home/subrat/JoCoR-env/Noisy_final_encoded\", transform=None):\n",
    "#         self.csv_data = pd.read_csv(csv_file)\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.csv_data)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         label=self.csv_data.loc[index, 'dx']\n",
    "#         img_path = self.csv_data.loc[index, 'image_id']\n",
    "#         #img_path = os.path.join(root_dir, (annotations.iloc[index, 1] + '.jpg'))\n",
    "#         image = io.imread(img_path)\n",
    "# #         y_label = torch.tensor(int(self.annotations.iloc[index, 2]))\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BACH(Dataset):\n",
    "    def __init__(self, csv_file=\"/home/subrat/JoCoR_bach/Data/Clean_train_data_encd.csv\", transform=None):\n",
    "        self.csv_data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label=self.csv_data.loc[index, 'label']\n",
    "        img_path = self.csv_data.loc[index, 'Name']\n",
    "#         print(img_path)\n",
    "        #img_path = os.path.join(root_dir, (annotations.iloc[index, 1] + '.jpg'))\n",
    "        img_path = os.path.join(root_dir,img_path)\n",
    "        #print(img_path)\n",
    "        image = io.imread(img_path)\n",
    "        #print(image.shape)\n",
    "\n",
    "        image = img_as_ubyte(exposure.rescale_intensity(image))\n",
    "        plt.imshow(image, cmap=None)\n",
    "#         transform = transforms.Resize((300,350))\n",
    "#         resized_img = transform(image)\n",
    "#         print(resized_img.shape)\n",
    "#         y_label = torch.tensor(int(self.annotations.iloc[index, 2]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjw9p76ntAa_"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "kZxbYxDYtCaH"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import numpy as np\n",
    "import torch\n",
    "import codecs\n",
    "from JoCoR.data.utils import noisify\n",
    "\n",
    "\n",
    "class HAM10000(data.Dataset):\n",
    "#     \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "\n",
    "#     Args:\n",
    "#         root (string): Root directory of dataset where ``processed/training.pt``\n",
    "#             and  ``processed/test.pt`` exist.\n",
    "#         train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "#             otherwise from ``test.pt``.\n",
    "#         download (bool, optional): If true, downloads the dataset from the internet and\n",
    "#             puts it in root directory. If dataset is already downloaded, it is not\n",
    "#             downloaded again.\n",
    "#         transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "#             and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "#         target_transform (callable, optional): A function/transform that takes in the\n",
    "#             target and transforms it.\n",
    "#     \"\"\"\n",
    "#     urls = [\n",
    "#         'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "#         'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "#         'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "#         'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "#     ]\n",
    "#     raw_folder = 'raw'\n",
    "#     processed_folder = 'processed'\n",
    "#     training_file = 'training.pt'\n",
    "#     test_file = 'test.pt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False,\n",
    "                 noise_type=None, noise_rate=0.2, random_state=0):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.dataset='/home/subrat/JoCoR-env/archive/HAM10000_images_part_1/'\n",
    "        self.noise_type=noise_type\n",
    "\n",
    "#         if download:\n",
    "#             self.download()\n",
    "\n",
    "#         if not self._check_exists():\n",
    "#             raise RuntimeError('Dataset not found.' +\n",
    "#                                ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
    "\n",
    "            if noise_type != 'clean':\n",
    "                self.train_labels=np.asarray([[self.train_labels[i]] for i in range(len(self.train_labels))])\n",
    "                self.train_noisy_labels, self.actual_noise_rate = noisify(dataset=self.dataset, train_labels=self.train_labels, noise_type=noise_type, noise_rate=noise_rate, random_state=random_state)\n",
    "                self.train_noisy_labels=[i[0] for i in self.train_noisy_labels]\n",
    "                _train_labels=[i[0] for i in self.train_labels]\n",
    "                self.noise_or_not = np.transpose(self.train_noisy_labels)==np.transpose(_train_labels)\n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            #if self.noise_type is not None:\n",
    "            if self.noise_type != 'clean':\n",
    "                img, target = self.train_data[index], self.train_noisy_labels[index]\n",
    "            else:\n",
    "                img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "#     def download(self):\n",
    "#         \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "#         from six.moves import urllib\n",
    "#         import gzip\n",
    "\n",
    "#         if self._check_exists():\n",
    "#             return\n",
    "\n",
    "        # download files\n",
    "#         try:\n",
    "#             os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "#             os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "#         except OSError as e:\n",
    "#             if e.errno == errno.EEXIST:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 raise\n",
    "\n",
    "#         for url in self.urls:\n",
    "#             print('Downloading ' + url)\n",
    "#             data = urllib.request.urlopen(url)\n",
    "#             filename = url.rpartition('/')[2]\n",
    "#             file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "#             with open(file_path, 'wb') as f:\n",
    "#                 f.write(data.read())\n",
    "#             with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "#                     gzip.GzipFile(file_path) as zip_f:\n",
    "#                 out_f.write(zip_f.read())\n",
    "#             os.unlink(file_path)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, '/home/subrat/JoCoR-env/archive/HAM10000_images_part_1/')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, '/home/subrat/JoCoR-env/archive/HAM10000_images_part_1/'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, '/home/subrat/JoCoR-env/archive/HAM10000_images_part_2/')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, '/home/subrat/JoCoR-env/archive/HAM10000_images_part_2/'))\n",
    "        )\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "\n",
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "\n",
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2049\n",
    "        length = get_int(data[4:8])\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        return torch.from_numpy(parsed).view(length).long()\n",
    "\n",
    "\n",
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2051\n",
    "        length = get_int(data[4:8])\n",
    "        num_rows = get_int(data[8:12])\n",
    "        num_cols = get_int(data[12:16])\n",
    "        images = []\n",
    "        parsed = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "        return torch.from_numpy(parsed).view(length, num_rows, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuKYV7DtvjTf"
   },
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipvP78kdvlC8"
   },
   "source": [
    "cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "oAqFwUuPtKmn"
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.init as init \n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "\n",
    "# def call_bn(bn, x):\n",
    "#     return bn(x)\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, input_channel=3, n_outputs=10, dropout_rate=0.25, momentum=0.1):\n",
    "#         self.dropout_rate = dropout_rate\n",
    "#         self.momentum = momentum\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.c1=nn.Conv2d(input_channel, 64,kernel_size=3,stride=1, padding=1)\n",
    "#         self.c2=nn.Conv2d(64,64,kernel_size=3,stride=1, padding=1)\n",
    "#         self.c3=nn.Conv2d(64,128,kernel_size=3,stride=1, padding=1)\n",
    "#         self.c4=nn.Conv2d(128,128,kernel_size=3,stride=1, padding=1)\n",
    "#         self.c5=nn.Conv2d(128,196,kernel_size=3,stride=1, padding=1)\n",
    "#         self.c6=nn.Conv2d(196,16,kernel_size=3,stride=1, padding=1)\n",
    "#         self.linear1=nn.Linear(256, n_outputs)\n",
    "#         self.bn1=nn.BatchNorm2d(64, momentum=self.momentum)\n",
    "#         self.bn2=nn.BatchNorm2d(64, momentum=self.momentum)\n",
    "#         self.bn3=nn.BatchNorm2d(128, momentum=self.momentum)\n",
    "#         self.bn4=nn.BatchNorm2d(128, momentum=self.momentum)\n",
    "#         self.bn5=nn.BatchNorm2d(196, momentum=self.momentum)\n",
    "#         self.bn6=nn.BatchNorm2d(16, momentum=self.momentum)\n",
    "\n",
    "#     def forward(self, x,):\n",
    "#         h=x\n",
    "#         h=self.c1(h)\n",
    "#         h=F.relu(call_bn(self.bn1, h))\n",
    "#         h=self.c2(h)\n",
    "#         h=F.relu(call_bn(self.bn2, h))\n",
    "#         h=F.max_pool2d(h, kernel_size=2, stride=2)\n",
    "\n",
    "#         h=self.c3(h)\n",
    "#         h=F.relu(call_bn(self.bn3, h))\n",
    "#         h=self.c4(h)\n",
    "#         h=F.relu(call_bn(self.bn4, h))\n",
    "#         h=F.max_pool2d(h, kernel_size=2, stride=2)\n",
    "\n",
    "#         h=self.c5(h)\n",
    "#         h=F.relu(call_bn(self.bn5, h))\n",
    "#         h=self.c6(h)\n",
    "#         h=F.relu(call_bn(self.bn6, h))\n",
    "#         h=F.max_pool2d(h, kernel_size=2, stride=2)\n",
    "\n",
    "#         h = h.view(h.size(0), -1)\n",
    "#         logit=self.linear1(h)\n",
    "#         return logit\n",
    "\n",
    "# class MLPNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MLPNet, self).__init__()\n",
    "#         self.fc1 = nn.Linear(28 * 28, 256)\n",
    "#         self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 28 * 28)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.init as init \n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "\n",
    "# class MLPnet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.layers = nn.Sequential(\n",
    "#         nn.Flatten(),\n",
    "#         nn.Linear(450 * 600 * 3, 64),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Linear(64, 5)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #x = x.view(16, 3 * 450 * 600)\n",
    "#         #x = F.relu(self.fc1(x))\n",
    "#         #x = self.fc2(x)\n",
    "#         return self.layers(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Set device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Hyperparameters\n",
    "# in_channel = 3\n",
    "# num_classes = 5\n",
    "# learning_rate = 1e-3\n",
    "# batch_size = 16\n",
    "# num_epochs = 1\n",
    "\n",
    "# # Load Data\n",
    "# transform=transforms.ToTensor()\n",
    "# dataset = HAM10000(transform=transform)\n",
    "\n",
    "# # Dataset is actually a lot larger ~25k images, just took out 10 pictures\n",
    "# # to upload to Github. It's enough to understand the structure and scale\n",
    "# # if you got more images.\n",
    "\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "# # train_set, test_set = torch.utils.data.random_split(dataset, train_set[0],test_set[0])\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "# # print(train_loader.label)\n",
    "# print(f'No of batch loaded for training: {len(train_loader)}')\n",
    "# # Model\n",
    "# model = torchvision.models.googlenet(pretrained=True)\n",
    "# model.to(device)\n",
    "\n",
    "# # Loss and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Train Network\n",
    "# for epoch in range(num_epochs):\n",
    "#     losses = []\n",
    "\n",
    "#     for batch_idx, batch in enumerate(train_loader):\n",
    "#         # Get data to cuda if possible\n",
    "# #         print(batch_idx, batch[0].size(),\n",
    "# #           batch[1].size())\n",
    "# #         print(f'data is :', data)\n",
    "\n",
    "#         data = batch[0]\n",
    "#         targets = batch[1]\n",
    "#         data = data.to(device=device)\n",
    "#         targets = targets.to(device=device)\n",
    "# #         \n",
    "#         # forward\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, targets)\n",
    "\n",
    "#         losses.append(loss.item())\n",
    "\n",
    "#         # backward\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "\n",
    "#         # gradient descent or adam step\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n",
    "\n",
    "# # Check accuracy on training to see how good our model is\n",
    "# def check_accuracy(loader, model):\n",
    "#     num_correct = 0\n",
    "#     num_incorrect = 0\n",
    "#     num_samples = 0\n",
    "#     model.eval()\n",
    "    \n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for x, yT, yF in loader:\n",
    "#             x = x.to(device=device)\n",
    "#             yT = yT.to(device=device)\n",
    "#             yF = yF.to(device=device)\n",
    "#             #print(yT.numpy()) \n",
    "           \n",
    "\n",
    "#             scores = model(x)\n",
    "#             _, predictions = scores.max(1)\n",
    "#             num_correct += (predictions == yT).sum()\n",
    "#             num_incorrect += (predictions == yF).sum()\n",
    "#             num_samples += predictions.size(0)\n",
    "\n",
    "#         print(\n",
    "#              f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "#         )\n",
    "\n",
    "#         model.train()\n",
    "\n",
    "\n",
    "# print(\"Checking accuracy on Training Set\")\n",
    "# check_accuracy(train_loader, model)\n",
    "\n",
    "# print(\"Checking accuracy on Test Set\")\n",
    "# check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRy1jeQGvvHq"
   },
   "source": [
    "main.**py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vcvjwynRvubl",
    "outputId": "a2c6378e-3f41-4e82-a5ba-8c738f4d05e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.BACH object at 0x7f44d10a5b80>\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "# from JoCoR.data.cifar import CIFAR10, CIFAR100\n",
    "# from JoCoR.mnist_HAM import HAM10000\n",
    "import argparse, sys\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lr', type=float, default=0.001)\n",
    "parser.add_argument('--result_dir', type=str, help='dir to save result txt files', default='results')\n",
    "parser.add_argument('--noise_rate', type=float, help='corruption rate, should be less than 1', default=0.2)\n",
    "parser.add_argument('--forget_rate', type=float, help='forget rate', default=None)\n",
    "parser.add_argument('--noise_type', type=str, help='[pairflip, symmetric]', default='pairflip')\n",
    "parser.add_argument('--num_gradual', type=int, default=2,\n",
    "                    help='how many epochs for linear drop rate, can be 5, 10, 15. This parameter is equal to Tk for R(T) in Co-teaching paper.')\n",
    "parser.add_argument('--exponent', type=float, default=1,\n",
    "                    help='exponent of the forget rate, can be 0.5, 1, 2. This parameter is equal to c in Tc for R(T) in Co-teaching paper.')\n",
    "parser.add_argument('--dataset', type=str, help='mnist, cifar10, or cifar100', default='bach')\n",
    "parser.add_argument('--n_epoch', type=int, default=200)\n",
    "parser.add_argument('--seed', type=int, default=1)\n",
    "parser.add_argument('--print_freq', type=int, default=50)\n",
    "parser.add_argument('--num_workers', type=int, default=4, help='how many subprocesses to use for data loading')\n",
    "parser.add_argument('--num_iter_per_epoch', type=int, default=400)\n",
    "parser.add_argument('--epoch_decay_start', type=int, default=80)\n",
    "parser.add_argument('--gpu', type=int, default=None)\n",
    "parser.add_argument('--co_lambda', type=float, default=0.1)\n",
    "parser.add_argument('--adjust_lr', type=int, default=1)\n",
    "parser.add_argument('--model_type', type=str, help='[mlp,cnn]', default='cnn')\n",
    "parser.add_argument('--save_model', type=str, help='save model?', default=\"False\")\n",
    "parser.add_argument('--save_result', type=str, help='save result?', default=\"True\")\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# Seed\n",
    "torch.manual_seed(args.seed)\n",
    "if args.gpu is not None:\n",
    "    device = torch.device('cuda:{}'.format(args.gpu))\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = 5\n",
    "learning_rate = args.lr\n",
    "\n",
    "# load dataset\n",
    "# if args.dataset == 'HAM10000':\n",
    "#     input_channel = 3\n",
    "#     num_classes = 7\n",
    "#     init_epoch = 10\n",
    "#     filter_outlier = True\n",
    "#     args.epoch_decay_start = 40\n",
    "#     args.model_type = \"mlp\"\n",
    "#     args.n_epoch = 200\n",
    "#     dataset = HAM10000(root='./home/subrat/JoCoR-env/archive/HAM10000_images_part_1/',\n",
    "#                           train=True,\n",
    "#                           transform=transforms.ToTensor(),\n",
    "#                           noise_type=args.noise_type,\n",
    "#                           noise_rate=args.noise_rate\n",
    "#                           )\n",
    "#     print(dataset)\n",
    "#     test_dataset = HAM10000(root='/home/subrat/JoCoR-env/archive/HAM10000_images_part_1/',\n",
    "#                          train=False,\n",
    "#                          transform=transforms.ToTensor(),\n",
    "#                          noise_type=args.noise_type,\n",
    "#                          noise_rate=args.noise_rate\n",
    "#                          )\n",
    "\n",
    "# if args.dataset == 'cifar10':\n",
    "#     input_channel = 3\n",
    "#     num_classes = 10\n",
    "#     init_epoch = 20\n",
    "#     args.epoch_decay_start = 80\n",
    "#     filter_outlier = True\n",
    "#     args.model_type = \"cnn\"\n",
    "#     # args.n_epoch = 200\n",
    "#     train_dataset = CIFAR10(root='./data/',\n",
    "#                             download=True,\n",
    "#                             train=True,\n",
    "#                             transform=transforms.ToTensor(),\n",
    "#                             noise_type=args.noise_type,\n",
    "#                             noise_rate=args.noise_rate\n",
    "#                             )\n",
    "\n",
    "#     test_dataset = CIFAR10(root='./data/',\n",
    "#                            download=True,\n",
    "#                            train=False,\n",
    "#                            transform=transforms.ToTensor(),\n",
    "#                            noise_type=args.noise_type,\n",
    "#                            noise_rate=args.noise_rate\n",
    "#                            )\n",
    "\n",
    "# if args.dataset == 'cifar100':\n",
    "#     input_channel = 3\n",
    "#     num_classes = 100\n",
    "#     init_epoch = 5\n",
    "#     args.epoch_decay_start = 100\n",
    "#     # args.n_epoch = 200\n",
    "#     filter_outlier = False\n",
    "#     args.model_type = \"cnn\"\n",
    "\n",
    "\n",
    "#     train_dataset = CIFAR100(root='./data/',\n",
    "#                              download=True,\n",
    "#                              train=True,\n",
    "#                              transform=transforms.ToTensor(),\n",
    "#                              noise_type=args.noise_type,\n",
    "#                              noise_rate=args.noise_rate\n",
    "#                              )\n",
    "\n",
    "#     test_dataset = CIFAR100(root='./data/',\n",
    "#                             download=True,\n",
    "#                             train=False,\n",
    "#                             transform=transforms.ToTensor(),\n",
    "#                             noise_type=args.noise_type,\n",
    "#                             noise_rate=args.noise_rate\n",
    "#                             )\n",
    "\n",
    "if args.forget_rate is None:\n",
    "    forget_rate = args.noise_rate\n",
    "else:\n",
    "    forget_rate = args.forget_rate\n",
    "\n",
    "    \n",
    "# input_channel = 3\n",
    "# num_classes = 7\n",
    "# init_epoch = 10\n",
    "# filter_outlier = True\n",
    "# args.epoch_decay_start = 40\n",
    "# args.model_type = \"mlp\"\n",
    "# args.n_epoch = 200\n",
    "# dataset = HAM10000(root='./home/subrat/JoCoR-env/archive/HAM10000_images_part_1/',\n",
    "#                       train=True,\n",
    "#                       transform=transforms.ToTensor(),\n",
    "#                       noise_type=args.noise_type,\n",
    "#                       noise_rate=args.noise_rate\n",
    "#                       )\n",
    "# Load Data\n",
    "# transform for rectangular resize\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(512, interpolation=InterpolationMode.BILINEAR, max_size=None, antialias=None),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "# img = Image.fromarray(np.astype(np.uint8))\n",
    "\n",
    "\n",
    "# load dataset\n",
    "if args.dataset == 'bach':\n",
    "    input_channel = 3\n",
    "    num_classes = 4\n",
    "    init_epoch = 10\n",
    "    filter_outlier = True\n",
    "    args.epoch_decay_start = 40\n",
    "    args.model_type = \"mlp\"\n",
    "    args.n_epoch = 2\n",
    "\n",
    "\n",
    "\n",
    "dataset = BACH(transform=transform)\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "batch_size = 10   \n",
    "train_percentage = 0.4\n",
    "val_percentage = 0.3\n",
    "train_size = int(train_percentage * len(dataset))\n",
    "val_size = int(val_percentage * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Data Loader (Input Pipeline)\n",
    "#     print('loading dataset...')\n",
    "    \n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "    # train_set, test_set = torch.utils.data.random_split(dataset, train_set[0],test_set[0])\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=2)\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                                batch_size=batch_size,\n",
    "#                                                num_workers=args.num_workers,\n",
    "#                                                drop_last=True,\n",
    "#                                                shuffle=True)\n",
    "\n",
    "#     test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                               batch_size=batch_size,\n",
    "#                                               num_workers=args.num_workers,\n",
    "#                                               drop_last=True,\n",
    "#                                               shuffle=False)\n",
    "    # Define models\n",
    "    print('building model...')\n",
    "\n",
    "    model = JoCoR(args, train_dataset, device, input_channel, num_classes)\n",
    "    print(model)\n",
    "\n",
    "    epoch = 0\n",
    "    train_acc1 = 0\n",
    "    train_acc2 = 0\n",
    "\n",
    "    # evaluate models with random weights\n",
    "    test_acc1, test_acc2 = model.evaluate(test_loader)\n",
    "\n",
    "    print(\n",
    "        'Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f ' % (\n",
    "            epoch + 1, args.n_epoch, len(test_dataset), test_acc1, test_acc2))\n",
    "\n",
    "\n",
    "    acc_list = []\n",
    "    # training\n",
    "    for epoch in range(1, args.n_epoch):\n",
    "        # train models\n",
    "        train_acc1, train_acc2, pure_ratio_1_list, pure_ratio_2_list = model.train(train_loader, epoch)\n",
    "\n",
    "        # evaluate models\n",
    "        test_acc1, test_acc2, = model.evaluate(test_loader)\n",
    "\n",
    "        # save results\n",
    "        if pure_ratio_1_list is None or len(pure_ratio_1_list) == 0:\n",
    "            print(\n",
    "                'Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f' % (\n",
    "                    epoch + 1, args.n_epoch, len(test_dataset), test_acc1, test_acc2))\n",
    "        else:\n",
    "            # save results\n",
    "            mean_pure_ratio1 = sum(pure_ratio_1_list) / len(pure_ratio_1_list)\n",
    "            mean_pure_ratio2 = sum(pure_ratio_2_list) / len(pure_ratio_2_list)\n",
    "            print(\n",
    "                'Epoch [%d/%d] Test Accuracy on the %s test images: Model1 %.4f %% Model2 %.4f %%, Pure Ratio 1 %.4f %%, Pure Ratio 2 %.4f %%' % (\n",
    "                    epoch + 1, args.n_epoch, len(test_dataset), test_acc1, test_acc2, mean_pure_ratio1,\n",
    "                    mean_pure_ratio2))\n",
    "\n",
    "\n",
    "        if epoch >= 190:\n",
    "            acc_list.extend([test_acc1,test_acc2])\n",
    "\n",
    "    avg_acc = sum(acc_list)/len(acc_list)\n",
    "    print(len(acc_list))\n",
    "    print(\"the average acc in last 10 epochs: {}\".format(str(avg_acc)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "<bound method Module.parameters of MLPnet(\n",
      "  (layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=810000, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")>\n",
      "<bound method Module.parameters of MLPnet(\n",
      "  (layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=810000, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")>\n",
      "<__main__.JoCoR object at 0x7f44d10a2160>\n",
      "Evaluating ...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x1047552 and 810000x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[102], line 217\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m train_acc2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# evaluate models with random weights\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m test_acc1, test_acc2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] Test Accuracy on the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m test images: Model1 \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m Model2 \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    221\u001b[0m         epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mn_epoch, \u001b[38;5;28mlen\u001b[39m(test_dataset), test_acc1, test_acc2))\n\u001b[1;32m    224\u001b[0m acc_list \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[87], line 82\u001b[0m, in \u001b[0;36mJoCoR.evaluate\u001b[0;34m(self, test_loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     81\u001b[0m     images \u001b[38;5;241m=\u001b[39m Variable(images)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 82\u001b[0m     logits1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     outputs1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits1, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     84\u001b[0m     _, pred1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs1\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/JoCoR_new-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[22], line 22\u001b[0m, in \u001b[0;36mMLPnet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#x = x.view(16, 3 * 450 * 600)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#x = F.relu(self.fc1(x))\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#x = self.fc2(x)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/JoCoR_new-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/JoCoR_new-env/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/JoCoR_new-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/JoCoR_new-env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x1047552 and 810000x64)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cl9ryZdzpn5"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/MyDrive/JoCoR/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ql-2UeP8zhKn"
   },
   "outputs": [],
   "source": [
    "!python main.py --dataset cifar10 --noise_type symmetric --noise_rate 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8Yhc6qp-OJT"
   },
   "outputs": [],
   "source": [
    "!python main.py --dataset cifar10 --noise_type symmetric --noise_rate 0.5 --co_lambda 0.9"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
